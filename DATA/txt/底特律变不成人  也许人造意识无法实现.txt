Text: 爱吃妈妈，这个怎么念呀？疼酸吧。哦，那这个呢拉心疼哇，真好吃。哎哎，爸爸妈妈，你们怎么突然想起来带我来厦门了呀，你不知道了吧。十二月厦门还有一场核聚变呢，请家乡核聚变。兔耳厦门站即将在十二月十五十六日在思明区会展路幺九八号厦门国际会议展览中心 c 二馆举办权域挑战的规则，, Start Time: 5640
Text: 再次凝聚全场玩家的力量更多知名嘉宾也将会在现场与热情的玩家们互动打挑战，赢奖品核聚变。兔耳厦门站，我们等你来玩。你说大家好，欢迎收听最新家居户儿。今天我是西蒙。大家好，我是四十二，我是小李。哎，今天小小儿终于回来了啊，对，一个拖了了长长时间的节目比较忙两个月。, Start Time: 35550
Text: 对，然后说中章对中章忠征对今天带来这个人类意识的这个人造意识的第三期。对，是关于这个人造意识，搞不搞得出来的一期节目。对对对对，呃，肯定会被喷死在下面。对对对对，之前有人出出这这个疑疑义啊，在第二期的时候，对对，没有。因为我觉得这期会这个人造意识里更多人的领域。, Start Time: 107360
Text: 对，而且这个领域呢，我也不是一个领域的专家和大拿，就这种比较容易被喷。对，不过无所谓，我我又不在乎这个分享一下。对对，就是对呃，今天这期呢讲的是这个人造意识能不能实际实现，所以可能会技术性比较强。嗯，当然了，本来我也不是技术专家，所以技术性不会太强，而且会尝试给很多的例子来说明。, Start Time: 132220
Text: 嗯，包括就我觉得我们三个可以多互动一下，可以让这个节目可听性增加哦。我先我先抛出一个实际的例子啊，就是这个例子名头是很大的哦，人造意识里面肯定有一个特别重要的部分，是他与人对话的能力。这个在各个企业呢，都是嗯人工，也也是人工智能很前沿的一个引领域。不管是 amazon 啊还是 google system 打电话那个对 siri 跟逗逗乐啊，, Start Time: 155180
Text: 其中有一个公司叫 vovobott，这个 voy 这个 WOE bot。这个 voybot 呢是做这个人造这个这个对话里面很难的一个领域。他的愿景啊是做这个人工智能自动的情感情绪疏导和心理诊疗。我的妈他是要做这个，你你你要想象他能做出这个，那这个应该是挺接近人造意识，, Start Time: 181020
Text: 是吧？能解决这个问题，这个公司来头还非常大。之前百度的首席科学家吴文达嗯，这个吴文达本来就是人造，不是不是不是人造艺术，人工工智能已经大牛了嗯，大牛了。这个吴文达从百度离职之后呢，第一站，但也也已经离开了第一站，就是一个 voybobot t 这个首席科学家去了。, Start Time: 205710
Text: 对，就是 voybot t 公司来头是不小。然后这 voyybot 呢确实有一个 APP 在这个都可以下载，然后我会持续的关注下来来用一下啊，它本质上呢是个游戏，是个恋爱两程游戏。对我我首先得说啊，这个 voybot 是个 rubbish，就是是是烂了了。, Start Time: 225190
Text: 他现在还能实现的是这对话术选择，对话术选择。对他给你出一个东西里面很少的机会，你可以自己打话。然后你是在两个选择中选一个，然后你一旦打的话，他理解不了啊，他就跟你说那种片段化啊，我我知道了，我我们接着下一个话题，我就其实特别傻啊，特别傻。但我想说呢，这是我这期节目的基调，, Start Time: 243370
Text: 就我觉得人造艺术搞不成的哦，就是关键是没戏。对，没戏。这个博做这么傻傻不是他们傻，就这个这个太难了，这个东西真的太困难了，做不成。所以今天我们就来我就来说说我今天为什么觉得为什么觉得做不成？就我我这天基调就是我觉得我不是觉得能做成，而觉得我要我觉得要弄这个事情。, Start Time: 269420
Text: 这就是典型科科幻迷。就人类人类文明的意义就是说技术只要有这个方向，就一定要往这个方向作了。这这个死那叫搞不搞成到搞。对对对对，都要搞啊。对，反正现在要搞时候，我也拦不住，他们肯定要搞啊。对，那我觉得搞成好。我觉得先说第一个问题会想想说说就是就这个问题下面一定会有人问，, Start Time: 290540
Text: 之前不管是文章还是节目，下面都有人问我我我要先把这个问题破除一下，就我们聊人造意识是不是一定首先要有一个对意识的定义。嗯嗯，因为之前不管是意识的问题，还是意识问题，都有人说哎，这个没法定义聊它干嘛？对我我要说这个玩意儿就是没法定义，哎，但是没法定义，不代表就不能聊。, Start Time: 308550
Text: 哎，有一些非常基础的东西，我每天都会讨能论。嗯，比如说语言，比如说时间意识这种东西，你其实都很难给他一个定义，甚至跑这个词你要让奥利会竞走，你不能跑你这抬杠啊啊，跑有多意识，包包括哎他跑了，敌人跑了，你也知道跑这个词是很难定义的。他有很多意思，包括意识也一样，, Start Time: 327270
Text: 所以我认为不能定义，不代表不能聊。嗯，我可以举个例子，实际上我们是在医学上有判断意识的方法，对吧？一个人昏迷了，你看这个有没有恢复意识，这很重要的一步。对，有个叫格拉斯哥昏迷等级判断法，他基本上这么判断法的，他分三个东西，一个是眼睛反应，第二个身体反应，第三个语言反应嗯，, Start Time: 345865
Text: 眼二反应跟身体反应比较像我合并到一起说，第一个是看眼睛和身体有没有在你给予疼痛刺激的时候反应。嗯，对，你拿个针一扎。哎，他腿动了然，拿光晃晃，拿刀光晃眼睁开了。比如你拿针扎腿都不动，那就是深度会比了。对对，第二个呢，是看他有没有在没有外界刺激情况之下，就是就是眼睛那么睁开或怎么样。, Start Time: 369620
Text: 第三种，这都算是意识等级里面的表现。对，嗯，然后第三种呢就是再清醒一点，对，是能够响应你给他的命令，针眼就是你说针眼让他针眼，这是几个啊？对，这是几个人下得了，就是针眼跟那个身体运动，比如说身体运动。第第四个等级就出现自主的睁眼和身体运动。就比如说他自己伸手够杯子，, Start Time: 391620
Text: 那肯定就清醒了吧。是是你都没跟他说话，他睁眼看四周清醒了。嗯，最重最重要的是这个语言反应最下一层啊，临近昏迷是他完全没有语言反应。嗯，再往上一点点呢，是他发出那种不可识别的声音，嗯，就是 vimonbo 略对略。对，然后第三，然后再往上一层呢是发出语词，但是不合逻辑的。, Start Time: 413850
Text: 嗯，比如他说赵下下唐唐伙啊，那那是是逻辑辑，其实实对对对对，比如说他说这是不合逻辑的意思，糖伙太符符合逻这个，然后再往上就是他跟你对话，而且能够合逻辑。嗯，但对话和合逻辑其实还不一定有清晰的意识。清晰是最上的一层，是他能够认人时间和地点。对，跟你问他，你在哪？, Start Time: 435280
Text: 他说我在医院呢，哦，那很清醒了，他说现在是哪年？他说现在清朝，那可能还没清醒了，他在哪年？二零一八年哎，清醒了，他说我是谁，他你们是王医生啊，那清醒了嗯，对他能够认人认逻间的地识，对他就说明他清醒。这有个例子啊，朝浩老师这个白血病治疗的时候，嗯，他他写了一个他的那个经历。, Start Time: 459120
Text: 对对，没合合辑，有对他这个呃他深度治疗深度昏迷，恢复了就有这个阶段啊，有个阶段他会这个胡言乱语，而说话吐字非常清晰，说一堆一堆的，但是一点事都一点。所以在恢复的过程中都会经历这几个呃不一定都会逐渐会有这个意识。但是对对对，但这些就是你叫格拉斯哥昏迷症啊，然后这是我们判断意识的。, Start Time: 479360
Text: 但我想说，我们能不能用这个设计一个类似于图灵测试一样东西来测试机器有没有意识，其实不能对吧？对你问机器这是哪年？二零一八年有意识识啊，这怎么可能这么简单，对吧？我们是不能拿这个，但是这个问题很有意识，为什么？对，人就行，人一这样的，你就是啊这恢复意识。对，, Start Time: 501310
Text: 是你先天的。假设这个人有意识，嗯，因此这个测验呢对人有没有意识是有效的，对对机器却没有效，这里还有很有意思的。为什么？问的是时间、地点这些东西。比如在美国，他们问的是现在总统是谁啊？对你说现在总统是克林顿顿，咱们还没恢复意识，是特朗普。哎，你恢复意识识会问这个呀。, Start Time: 520290
Text: 对对，为什么是这些问题来看一个人是否恢复意识的这会引入到一个特别特别重要的话识。因为我们日常是不会这样的，我不会今天来来办公室说，哎这样我是谁？说李李后，我说行，好好，咱们接着聊，你要答不出来就不聊，是因为这些东西是最基础的常识。嗯，美国总统现在是谁？现在是二零一八年，, Start Time: 542840
Text: 我们现在身处北京，现在是深秋快捷，近冬天挺冷。嗯，这些话其实在构筑我们日常其他的思考和观点。但是在我们平时对话的时候呢，是绝对不会讲这些的。这些是最基础，最基础的常识，是因此在人造智，我们马上就会进入这个人造意识啊，在人造意识构建中一个最基础的问题就是常识问题。, Start Time: 562600
Text: 我们发现人造意识很能下围棋，能做很多事儿。但距离意识呢它会有一个很关键的阻碍，就是人造意识没有常识。我我得必必须让他有常识，它才能跟我们包括对话什么的，都在这个基础之上才能产生。就有没有形成最终的完全的模拟人的人造意识。咱们先不说啊，就说比较基础，比如跟我们对话这些的，, Start Time: 586640
Text: 它需要大量常识才能完成对话。但常识我觉得是可以灌输的。哎，我们就是要说这个问题题，常识这个东西是啥？首先常识这个词， common sense，他最基础的意思不是共通的知识 sense sensus 这个拉丁词汇，他应该说是共通的感觉。嗯，对，常识呢是我们共通的感觉。, Start Time: 607960
Text: 你这个观点特别符合今天这个人工智能他们的观点。嗯，他们认为一切感觉是可以知识化，以知识的方式灌输给机器的。因为我总觉得常识是客观的。你看我我就说我们在日常语言中用的两种描述常识的方法。比如说我们有的时候会说，哎呀，现在城市的小孩都缺乏农业常识。但我们这么说的时候呢，, Start Time: 631710
Text: 他是知识化的吧。比说我们说它五谷不分，它连麦子跟水稻分不清楚。对对，说明他没常识，但我们也有另外一种使用常识的方法。比如说哎呀这个人挺没常识的，尤其是这种人际沟通的方识。但我们这么说的时候，其实不是他缺乏某种知识，因为人际沟通是一整套隐而不宣的，规范是很多规范呢是高度情境化的。, Start Time: 654650
Text: 你也很难总结出来，它就是这么几条。而且你很难让一个人来把这这五条背了，他明天就有这个人际规范的常识，我们归纳为情商是吧？对，我们缺纳情商的表现。那实际上就是他之前，比如说在人际上吃的亏还不够多，嗯，啊被怼的少或者没谈过恋爱，所以他缺乏这种常识。像这种尝试其实是非知识的。, Start Time: 677870
Text: 是的，像我们在判断人有没有意识格拉斯哥恢复的时候呢，问的是一些跟知识相关的常识。但其实比如说你戳他腿他在动，你让他眼睛的一些反应啊，很多时候会带入一种非知识的尝试。嗯，但这个问题我们一会会说的更深啊，就是是不是第一，他是不是都能知识化。第二机器是不是知道这些知识就行了。, Start Time: 699250
Text: 嗯，那我再举另外个例子啊呃我们都知道一个常试这个吸烟有害健康，是这知识都知道，但我爷爷戒烟呢是他检查出肺结核的。第二天，他突然就被烟戒了。之前他戒了无数次烟，他都没戒掉，戒掉。嗯，我就会认为呢你爷爷之前并不真的知道抽烟有害有害健康。他掌握这个常识呢，是哎呦来了，, Start Time: 722300
Text: 比如好多人也是嘛，你酒驾危险，他都知道他哪天酒驾真是被警察拦一次，拘了十五天出来再不喝酒了。是就他真正掌握这个尝识呢，其实是他跟体验有关，跟跟体验有很大很大的关系。对，所以这个东西就是那机器有没有可可不可能有体验，这就是更重要的事情了。而且我觉得事实上这个词用的特别好，, Start Time: 749080
Text: 可以在这儿说就是体验和经历。嗯，这两个词是不一样，对吧？是的，我们可以说呃，比如你说哇过山车太好玩了，然后我我可以这么说是合理的。我说哎呀，我去坐过山车，但就没你的体验，对吧？是，也就说经历呢是一个比较外在的东西，嗯，体验呢是个内在经历之后比较内在的东西。, Start Time: 771640
Text: 而很多常识呢恰恰恰是跟体验相关的。也就是说我们会认为我们能让机器人经历，比如说阿尔法狗，他一天下好几百万盘棋。李世石他的经历比阿尔法狗呢就少很多。但你要说这两个人对围棋谁有体验，就阿尔法狗有没有对围棋的体验？没有，我不知道，我觉得这个挺挺挺有争议的。比如有人就会认为可能有，, Start Time: 794680
Text: 但不管怎么说，围棋你可能有啊，但很多别的东西呢，就比如说这个 v bat，嗯，比如说一个心理医生在经历跟患者对话的时候，他有很强烈的内在体验。那这个 v boat 在跟患者对话的时候有没有体验？至少现在我们会认为嗯这可能就没有，对吧？如果没有这个体验呢，很多尝试他就没有很多尝试。, Start Time: 818560
Text: 没有，并不是说那就无所谓嘛。机器有没有体验？如果很多这个尝试没有了，在下围棋这种纯粹理性的事情上，你没体验就可能无所谓。但心理诊疗这种事情啊，对你要没体验对话这种东西你要没体验，你就胡言乱语。嗯，很多很关键地方呢你就做不到，做不到呢你就都别说真的，有没有意识啊，, Start Time: 839800
Text: 你也不会被我们认为有意识。嗯，因为经常你跟 google 对话， google system 或 siri，平时又问个天气，啥设个闹钟还行，稍微多聊几句，他都不知道，就是不好意思。这个问题我回答不了，我给你提供一搜索结果，你看是不是你要你做，对吧？就这种问题其实很困难。, Start Time: 862060
Text: 所以说其中有个特别重要的东西啊，就是第一个跟人造智意识相关的，绕不开的就是常识。如何让机器拥有常识。但这个常识呢，像我们刚才也区分了常识呢，就有知识的常识，有非知识的常识，这个非知识的尝试我还要更多说一句，即便在人生上都比较难，就比如说一个人从来没谈过恋爱，, Start Time: 879100
Text: 嗯，他说哎呀，太想获得关于这个恋爱的经验了。他后然后他就上网去学那个 PUA，然他说他就调调女孩谈谈三个月谈分手了。然后我我我们可能就问他他就三个月之后，你真的爱过这女孩嘛？他说没有，反正我追到手了，谈了分了。那我们可能我们可能就会说，那你还没有谈恋爱。对啊，, Start Time: 903640
Text: 对你没有谈恋的经验是也就是说这个经历跟体验哈，还跟很多现在的东西有关。嗯，就很多体验的获得，对很多体验的获得，你得得有那个能力，你才有这个体验，是像谈恋爱这种这种这种经验或者爱的经验，人的感情的经验，你得先有那个能力，这个体验才会有。嗯，因此我们在赋予机器常识的这部呢，, Start Time: 924980
Text: 这个常识本身呢就变得非常非常复杂。现在我们有能力赋予机器知识类的尝识，这这当然有能力，对吧？是一会儿会说这个其实都挺挺难的。是的，我们觉得有些知识挺容易的。比如特朗普是美国的总统，他他一任是奥巴，马上一任是是是小布布什这些挺容易的。而且这种机器尝试的机器知识库，, Start Time: 950090
Text: 实际上在很早之前就有人做了九十年就有人做。是的，这个库现在是个开源库，叫 word net，已经很完善了，里面有各种各样的知识。而像什么 assistance、 ant、 siri 这些，它最基础的知识库掉的还就是呃 word net 库，他以各种检索方式再再用算法去算，, Start Time: 970610
Text: 这个是很多的。但是我们一会儿一会儿我们再再说到常识，会看到具体说这个他们现在已经实现了，哪一步会发现，其实常识呢比这个问题也会复杂很多。嗯，这里就涉及到一个我可以介绍的东西。就是我我们知道现在这个世界基本上的不管是哲学观念啊，还是深到我们每个人的日常观念。, Start Time: 990085
Text: 呃，如果说他第一肯定是来自自欧，嗯，我们现在的世界是一个西方化的世界。如果我们把西欧世界分成两部分，分成英国和大陆的话呢，现在整个世界基本上是在英国的那套思想之下。是的，传承下来更多的是一个英美的，它比较偏重经济学经验主义、实用主义等等的。但其实在英国对于经验主义呢也有两个基础。, Start Time: 1013295
Text: 嗯，这两个基础就是今天我们社会的两个挺针锋相对的基础。而人工智能和人造意识呢就在走其中的一条路。嗯，就对于经验的基础有两个人，有两个不同的观点，一个是休磨，一个是洛克。嗯，洛克把构成经验的基础称之为 sse data 哦，就是由不同的感觉的数据数，它它叫 data，, Start Time: 1037660
Text: 就感觉的材料材料构成的。这个 since data。在洛克的观点里，他这种 data 你都大概能听出来这个词，它是可以高度知识化或者客观客观，它叫做经验。原原子嗯是可以原子化的，变成一个一个小的单元，嗯，一到这个呢数学家就可以上扬。那这个我可以把它数学化，, Start Time: 1061590
Text: 这这东西我可以给公式。那现在我们对于科技有非常乐观的心态，嗯，有这个觉得人造意识可能成型，觉得人工智能挺好，觉得人的意识是个虚望。嗯，你大概都会从这个角度去认识，就是我们是从不同的感觉经验来的。比如说我们会认为呃火燎着我疼和分手了，伤心可能有一种构成他们俩共同基础的恶感，, Start Time: 1081330
Text: 嗯，那都是不好，这个不好在这儿呢基本上叫心痛，在那边呢叫皮疼肉疼，但他们都都反正是疼嘛，痛火对我们构建人造艺识呢，我们就给他一疼。这个疼呢我们把这个疼演化成四万种不同的藤法，针扎藤火烧藤，这个国破山河疼，这个丰生疼。对，这都可以啊。这是藤法，但休磨是另外一个方法，, Start Time: 1109790
Text: 嗯，要休磨管这种基础的感受就叫 sensation。意思是说我就就休默就不说声了。但意思是说，休末会认为我们是不可能知道有哪些东西必然的导向一个感觉的。因为休莫是否定因果论的嘛，所以休克人我们能知道的呢就是感觉感觉是我们最基础的东西，从感觉出发。嗯，但感觉有没有一个 sense data 在后面必然的促进，, Start Time: 1134030
Text: 感觉没有没有，或者我们或者有你也不能说他就一定是这样。嗯，对，这是两个相当不同的路径了。那么现在基本上就在洛克的基础上建基起来的。嗯，那我们现在就要进入到第二个我们探讨的。就既然 sense data 和 sense 行不行呢？其实他要说的呢是关于我们知觉的问题。, Start Time: 1161450
Text: 嗯，而我们现在呢确实也在给人工智能赋予知觉，尤其是视觉，对吧？但不管是自动驾驶车是还是认猫认狗认人脸嗯，接上这些监视探头是认你也是希望认我你跟你的身份证号、关联说多了，就这些都是跟知知高度相关的。那么我们在比这个问人造意识能不能获得常识更深一层的，就是我们能不能给人造意识知觉？, Start Time: 1182280
Text: 那现在我们能看到的呢是人造意识，人工智能能看能听，对这种东西都行。嗯，但这个呢是不是知觉就需要我们进一步的分辨，就是我们的知觉基本上可以把它分成三类知觉，我们大家都都应该能理解。第一个是叫叫主体知觉。嗯，就首先我能意识到我是特强烈的。你只要一回忆，我左指上识了什么，, Start Time: 1209280
Text: 你就能意识到你你我存在在的。第二个呢，我们有目标的直觉，这是很明显的。我想可聊喝水嗯，就是要要喝水，这个东西啊是可直接可以被我们 sense 到的渴水。第三个呢就是就是身体知觉，就是我摸着了，我闻着了，我看着了。但这个第一个主体知觉我们先不说啊，今天都可以不用讲。, Start Time: 1234740
Text: 嗯，因为你他如果有主体知觉了，他应该就是人造异识了，他都用我的感知了。这个能不能实现这是氧氧鸡氧氧蛋的问题，咱不打就讲后两个，我们就从这个身体知觉开始讲。其实这个身体知觉啊就其实已经挺复杂的了。就拿看这个东西来讲，就是第一我们跟计算机最大的区别，就人的看的知觉在绝大情况之下是视而不见。, Start Time: 1261860
Text: 对，嗯，也就是说马上知觉就涉及到一个很很复杂的问题，人的知觉是有注意力的。其实比如说自动驾驶汽车，嗯，他的直觉是没有所谓注意力这档的对他一下就把你眼前所有东西识别出来，这是墙，这是卡车，这是行走的人，这是狗，但人是按理说你视网膜其实啥都看到了。嗯，但比如现在我就看到新闻，, Start Time: 1291425
Text: 我过过来看着四十二，其实新纹在我的视网膜里，但是对识别不出来。再就比如像像这个鸡块子脑袋这识别出来，我们老说熟识无睹嘛，真的会是你你你你门口有一个坎儿，这坎竟然拿水泥填上了。你天天都看着他，你其实看着他，你走在那摔一跤摔跟头，对吧？其实你是看到的听啊、触摸啊都一样，, Start Time: 1316700
Text: 就是机器呢能看能听，但机器没有注意力，我们有注意力，这点就很不一样。一会我们讲注意的时候会发现这还有一个更深的区别。第二个目标感知，比如说李世石在下围棋的时候有个目标，然后阿尔法狗在下围棋有个目标，在这个目标上呢，他们俩可能还挺像的。是，但我们知道日本之前在被这个哎那个大师叫什么亲源的，, Start Time: 1336240
Text: 无无缘嗯在被无亲缘大师深度的改造值的。而且很多围棋门派这个流派那个流派还不是今天阿尔法狗和李世石那个目标。嗯，他们有更多的目标，这个棋要和谐要美。对，甚至有的流派认为就是要下和棋。对，下到谁也赢不了，是是才棋，这才是最高级的围棋，对吧？所以机器的目标大概我们如果说啊简单点说机器最容易追求那种数量最大化的目标，, Start Time: 1362410
Text: 能够转化成为一个大大值值的目标，是器器容容易感的。嗯，但人的目标呢，当然现代社会人的很多目标也能够转化数量最大值的是。而且说句实话的话，下和棋的个目目标其实也能转化出一个数学最大值。嗯，但比如有些流派认为不光要下和棋那个局面还得美。嗯，这个东西能不能转换数学目标呢？, Start Time: 1390090
Text: 就有争议了，也就是是对，也就说人其实有很多目标呢，至少至少我们经常会做一些事。是比如说哎呀这个人太不理性了，一个量化的是吧？不，他即使能量化，它都是量化里面不赢的那个。嗯，比如我们说这人太一根筋，脑子太轴了，不理性。大概意思就是说明显他最后选这个东西不是利益最大化的。, Start Time: 1412100
Text: 嗯嗯，特别谈恋爱，爱孩孩谈恋爱，非要跟人复合。这种事情就是特效啊，这种事情你看这个太不理性了。所以人的目标呢虽然都有目标感知，我们可以说机器有目标感知，阿尔法构想赢。我们说啊这是某种目标感知。我们姑且说是嗯，虽然虽然我也认为不是啊，现想姑且说是，但我们也认为人的目标感知呢比那个说是吧？, Start Time: 1434560
Text: 那这个东西还是第一层的，不太一样的，马上就有第二层不太一样的。第二层不太一样呢，就是我们的感知是可以内生的，就包括刺激感知。我现在立马就可以脑子里想着一个特别血腥的场面，然后觉得我操太疼了。是，比如我现在想海沃德去年崴脚，我现在想怎么想，我的右脚踝就嗯就有感觉，, Start Time: 1455320
Text: 我操太疼了。就是我们可以不管是身体感知等等的，我们可以自己刺激自己，我们可以完全脱离外界刺激。我就自己给自己施加一刺激，包括这个内审感知也一样，目标感知也一样。就我可以想一个外界目标，我要把这个水平挪到那儿去，我也可以完全想我自己人人天天想我自己要成长，我要变成更强大这种屁话，, Start Time: 1479540
Text: 就人天天想。所以说我们不管是身体感知还是目标感知都可以，你就坐那儿想想琢磨，你就自己琢磨出来。嗯，但是对机器来讲呢，但你可以说阿尔法狗自己给自己下围棋，那不叫内生感知啊。嗯那个其实已经是在设计另外一个阿尔法狗去。是的，互相刺激。嗯，包括那个呃那个阿克拉 boston dynamic 那个机器人，, Start Time: 1501880
Text: 你必须给他外生刺激。你说我靠，你自己来想出去琢磨动作不行，这还是需要外部输入跟外界反应啊，包括那个现在图像识别引擎认猫认狗这东西还为什么要监督式学习啊？他说自己搞不定，还得雇好多产业工人，天天坐在那给你描边。对对对，看我那报道吗？报道特别有引人触动，就是现在兴起一种新的工作，, Start Time: 1525210
Text: 就是去教人工智能。但这些工作服务什么？对这些工作还不是说你是个程序员，他是很低级的工作。你就坐在那儿跳就出猫和狗，对了吗？你就对错，你就点错，你就用这样去教他辅导他学习是吗？对，里面识别人的边上，你就一天，你要处理，可能好几千张照片。你处理的方式呢，就是给这个图像上人描边，, Start Time: 1551740
Text: 你打点哦描边，然后下一张给这个描边哦这些东西去训练机器人，这是个纯体，让他们识别这个轮廓什么的。对的，这就纯体的劳动。但人比说人可以很快速学会的东西，但机器需要海量数据，而且就需要外部自激去做。嗯，这这个产业工人这个问题。一会儿我们结尾还会说，就是就现在人造造这个路径和人工智能路径，, Start Time: 1574385
Text: 可能会生产出很多 sheet job，就是这种产业工人的工作是很很麻烦的。所以说这是第二层的复杂，我们人有内生，还有更复杂的。我说出来你们应该觉得还挺有意思的。就我们人还有一种感觉，就我们会感到空虚啊，而且空虚感是个真的感觉。就这我觉得包括我在在二位，就任何人都感到过空虚，, Start Time: 1596830
Text: 就觉得哎呀没什么意思。而且恰恰人是在感到空虚的时候，你产生出一种行动的意志。你说哎今儿我也找点乐子，是我得干点什么，干点什么，弄点刺激，这个感到空虚啊，这个东西就太困难了。你说让机器怎么感到空虚呢？这几乎是一个不合逻辑的事情，嗯，让机器感到空虚。你说我给你输能就叫空虚，, Start Time: 1622170
Text: 那你已经给他个什么东西了。就人感到空虚，恰恰恰是我们感受到一种种没有就啥也没有，就能给你一个感觉啊，就是很有意思很有意思。所以说我们在感知这个层面上，虽然现在机器看着挺厉害啊，也听得懂了，也看得出来了，也听得到就都有了。但其实我们的感知跟机器感知比较复杂的多，, Start Time: 1645980
Text: 就不还真不是我们无感，机器有无感就完了。就这个感知其实是非常非常复杂的。所以不管是知觉还是常识，本身呢都具有很高很高的复杂性。嗯嗯，所以说这些复杂性，我刚才说的部分，那应该知道对于机器来讲，这是挺难挺难去获得这种能力的那我们就来说说机器获得能力这个事嗯就是机器学习。, Start Time: 1665300
Text: 那么首先啊应该有一种这个技术路径会认为深度学习是个特别了不得的东西。嗯，机器获得意识的方法呢，其实就是它会到达某种复杂的临界点，它先获得，然后要翻过去，它就获得意识了。就是几乎所有嗯，我我看的的啊啊就四十二可以补充，现现在继续学习。因为是五大算法嘛，要求的就是现在有一种思路，, Start Time: 1688500
Text: 就是统一五大算法，就跟物理学要统一两种理论一样。统一完之后，他认为他会这个催生这个深度的算法，更深度的学习模式。啊，对，但是现在没做到啊。对，而且我觉得好好的好好的科幻小说，应该他的基础想象都是这样的。当他翻过个坎的一夜之间，他就意意识了，就因为他获得了意识。, Start Time: 1715520
Text: 对，而且我们会认为 deep leararning。我们现在认为啊 deep learning 是一个跟过去的灌输计算机不太一样的东西。第一呢它可以自学习嗯，确实有非监督学习的方法。嗯，比如说阿尔法 go，就是它可以自己跟自己下。第二呢机器学习仿佛是一个应用领域，, Start Time: 1734020
Text: 挺宽的东西，嗯，它可以拿来自动驾驶，它可以拿来下围棋，它可以拿来打 dota。嗯，好像它可以它可以拿来做对话，它可以过做很多事情。正是因为这个原因呢，我认我们认为人工智能开始具有那种丰富程度和复杂性。嗯，就是这个 deep learning 太厉害了，人工智能可以今天会有这个明儿会有那个它越来多越来越多，, Start Time: 1752220
Text: 可以推动它到达那个临界点。但我有一个完全不同的看法，就我认为整个 deep learning 本身啊嗯这是个是个语言的误用来的。就我认为 deep learning 本身并不 deep。首先这个 deep learning 本身的 deep 这个词并不是指向我们日常生活中觉得哎呀，, Start Time: 1774380
Text: 你照下这个人挺有深度的哦。所以人工智能这个深度它基本意思啊，其实是说过去的机器它作为一个刺激反应系统，是一层嗯嗯刺激反应。今天的所谓神经元网络，在刺激和反应层中间有不可见的很多的算法层。嗯，它的 depth 在原意上指的其实是这个跟过去不一样，现在中间有层级了。, Start Time: 1794350
Text: 嗯，因为有层级呢就可以用那五大算法。比如有层级的，你就可以用那个权重递减，他慢慢就可以产生出产生出这种深度了。所以说这个深度跟他在社会领域之中会具有深度，其实根本就是两个意思。这个 deep 就不那意思。但你也知道，今天很多记者写报道，他在为了追求所动角度，, Start Time: 1819840
Text: 包括这是公司，公司为了宣传他厉害，他都用那种潜面的游泳这种词基本上哎我们他会对话了。对，他就是什种呢？ depth 他好像说它是具有社会深度。首先我认为这个东西呢是不具有社会深度的。其次呢它跟过去的各种机器学习的方法相比，在一个基础的根源上是一模一样的。就是说到底它是个统计学，, Start Time: 1841600
Text: 嗯，只是用了不同的统计方法，它用了一种这种统计化这种技术，具体技术细节我们就是不说了。因统计的跟我们人判断有个很本质的区别。统计不管因果性，只管相关性嗯，对吧？所以说不管现在还是过去的人工智能深度学习，过去的非深度学习，他最后能够得出的就是这个东西啊，跟那个结果高度相关。, Start Time: 1866690
Text: 但不像我们人嗯，我们人很多时候呢，当然很多因果判断错的啊，但不管怎么说，我们更倾向向认为啊他因果关是因为他来的对，而不是相关性判断。而直到现在的深度学习依然是一种相关性的判断。所以说我我们先因此我们在进一步探讨之前呢，先抛出两个词，我们抛出抛除学习和智能这个词。, Start Time: 1891510
Text: 嗯，先甭管智不智能，先甭管它是不是学习，我们这不管啊，反正这玩儿就是一个基于统计，基于大数，最后找到相关性的那确实现在的东西发现相关性的能力呢比以前强，尤其是呢它不像以前就走到死胡同去了。嗯，现在这个可以有很多方法避免走进死胡同，其实能找到很强很强的相关性。, Start Time: 1915610
Text: 但不管如此，我我先说个有意思的东西啊，就这套东西的基础是从哪儿来的呢？是打二战打出来的。嗯，就之所以有这个玩意儿呢，是因为二战人，特别是美军，就人类从来没有面临过要如做这么大的决策。就对对，突然一下上来那个年代好几千亿的事情做一个决策。所以这个决策如此之重，, Start Time: 1935225
Text: 就一步走错，就是人类完蛋的决策。所以当时开始兴起了这个信息论和控制论，嗯，就是觉得这个美军的这个中央怎么参谋长联席会议吧。那会儿不我不知道，那会儿叫不叫参谋长联席会议啊，可能三军总司令部之类的啊，反正反正这个 head 怎么做决策，这么多数据涌来欧洲战场，, Start Time: 1960260
Text: 这死的这人这三个人调配后勤补给这怎么搞得了啊？然后计算运营对嗯出的这个控制论和系统论。而所有这些统计啊算法，基本上就是从那会儿或从那会儿之后开始的。其实人工智能的核心的算法，从七十年代之后没有更新过，就到现在还在用那个东。嗯，而那个东西就是从相农的信息论和这个控制论者维纳的控制论慢慢慢慢衍生出来的。, Start Time: 1981280
Text: 而所有这些东西最开始发明他的这套系统和这套观念吧。嗯，这套方法发明他的基础目的呢，他不是为了追求人类的福祉。这套基础目的是为了这少数的人，可以利用这个手段控制一个很大的局面。嗯嗯，因此呢我觉得首先对深度学习这事儿啊，我们看所有深度学习的例子。最后我们感觉是让让让让机器的智慧越来越强，, Start Time: 2010015
Text: 不是我度学习的。所有社会应用是让某些企业、个体政府靠他可以向二战美军操纵二战全局一样，就他们这几口子人就会控制这么大一块事，嗯，这本质上是来干这个的啊，所以我觉得大家大家特别希望人工智能人的快速发展。我说实话我就不是特别希望，我老觉得这都没发现哈。对我们的生活福祉好像帮助不是特别大。, Start Time: 2039610
Text: 嗯，他就是使用一个一个大的大规模的管理。他的意思就是说，过去算法就是算法一根筋是对算法本身不改变的。现在算法获得一个结果之后，可以反向过来改变权重啊参数啊。嗯， something 就 basically 就这样的东西。那深度学习神经元网络，就是这个反向过程的开始，, Start Time: 2066210
Text: 有不同的层次。在层次你可以用权重啊，不同的方式啊，有的是卷积的方式啊，有的是分类的方式啊，对它进行演算，基本上就这个东西。那这个东西好，就是技术东西说再多没什么意思啊。嗯嗯，好，这个东西其实啊在我看来，在我的认识里面，它的领域非常有限，它有很多很大的问题，, Start Time: 2084600
Text: 导致它其实没那么厉害。我先说它领域有限，今天我们看它可以做东做西。其实说下来不外乎是做四个事儿，语音识别嗯，图像识别嗯，语义识别游戏真的就没有不不能做更多的事情了。所以本质上它的相关性最好来做什么？以前机器干不了的事儿呢，就是模式识别，它能识别这玩意儿是啥？, Start Time: 2107340
Text: 以前机器做不到，现在能做能做到，而它能识别的模式，它能识别抽象模式吗？也不能它最容易识别的模式呢，就是就我刚才说那几个一个意思，而且意思这个现在我觉得还不能说的能能弄好啊。嗯，我举个简单的例子啊，比如现在机器翻译和机器的语义识别翻不过一个坎儿。这个坎儿呢又被乔姆斯基认为是人类语言最重要的特征。, Start Time: 2134950
Text: 就现在机器翻译和机器翻译和语义识别还翻不过递归这个坎儿嗯，是不是递归？就这个意思就是我上周跟西蒙聊天，说到他上个月跟四十二一起谈起他们去年去团建时候的一个事儿。嗯，对，这个东西我靠机器理解这种东西是非常困难的。但人理解这个你知道我们最后说的是不是这么说？我们最开始学英语做的阅读理解，, Start Time: 2159550
Text: 其实就是要就是培养对于英语的递归性，对吧？对，他说的是啥？对，这个对人来讲，其实你学的挺快的，嗯，就是脑子聪明的人看十句啊啊啊，英语的递归性这个意思啊，它里面的这个悬垂关系啊，嗯这个前后倒装关系是这个啊，他下次看看就会了，但机器现在确实能会挺多词了。呃，比如说你跟 siri 对话好了都能理解，, Start Time: 2185390
Text: 但你给他说一个递归信，两三层的嗯，根本不知道你在说什么。嗯，而乔姆斯基又认为呢人类语言最重要的特征就是递归性。所以说所以这个东西你要给乔布斯基说，乔布斯基肯定不不惊讶，他会让人家机器怎么可能能会这个的。嗯，他要会这个他就是人了啊，这是挺深的一个了。所以说我我只是从语言方面，, Start Time: 2209570
Text: 从语义方面来讲一讲就深度学习。其实它的应用范围啊，其实其他地方呢深度分深度学应用方案。就刚才那几个，当然图像识别就能做好多好多不同的事情。嗯，领域是很多的，但本质上也就是图像识别。但人的脑子比起类似这种东西啊，你你你做的事情可多得多。而且现在所谓的这个深度学习，, Start Time: 2229990
Text: 其实它有很多问题存在。导致在很多地方呢，即使图像识别，它也没法学会。第一个就是现在这种所谓这种神经元网络算法的深度学习。它首要呢它需要基于海量的数据，它对于数据量的需求是非常高的。比如说阿尔法狗为什么行？就是因为他确实可以自己跟自己下，它可以不同版本之间下，, Start Time: 2250165
Text: 他一天可以搞两三百万盘就挺好。为什么现在要雇产业工人去描边点？那猫猫狗狗的错误，包括那个就是自动驾驶那个公司需要上路测试，找人去路。而在计算机里面，让人去点去上路，拍一个上路测试不是上路真的开啊，是开上路去让，还是人开人开。但是机器判断墙车人回来播这个视频，, Start Time: 2272610
Text: 比如说哎这个车你没识别出来，嗯，确一下，说确认开。哎，这个人在在动，你没识别出来。哎，这个墙你没识别出来，你以为那是路的那是墙去调，它就不断的调，不断的调，不断的调。就是因为这个算法想稳定需要的数据量真的是非常非常大的。这一刀下去就砍掉了很多的事情。就比如说人工智能炒菜其实挺困难的。, Start Time: 2298820
Text: 嗯，所以炒菜结果的生成不像下棋那么快，下棋，但下的快可以下很多。比如炒菜炒出来人一长，嗯，咸了，你给他输一个咸了，然后再给你来一盘。这一炒十分钟炒串仔，这一盘你更咸了更咸了，你每十分钟来一次啊，太慢了。嗯，你雇一千个人，十分钟一天吃不了的，人肚量还有限的，, Start Time: 2324240
Text: 你分他老吃，像这种速度，你训练机器太慢了。就人工智能所需要的这个数据量真的是非常非常大的。很多日常利用领域的量都不够，它嗯就比说翻译现在其实翻译的语义量是太少了。对，就过去我们翻译机全找了，还不够他学翻译的事儿啊，所以首先这个东西呢就限制了它的应用，它其实还不是什么都能学，, Start Time: 2345620
Text: 很多领域就不具备这样的数据量，什么领域适合呢？比如说刚才我们看那个虚拟围棋跟吃饭是特别好的例子。凡是能够虚拟化，电子化的领域挺适合。对，就他都能够里面自己跟自己搞。嗯，凡是要跟日常生活产生接触的领域，其实都挺困难的。嗯，因为日常生活的流转率就没那么快。对，, Start Time: 2369750
Text: 就没那么多东西，就是它第一个它有好多好多问题啊。第二个，我们认为人工智能有一个好处是，哎，你看他又能干的又能干，那个是这个算法和方法，本身又能干，这又能干那个，但是它出来的应用对都极窄。你拿下围棋，这个都不知他打 dota 打的好不好，他就不能打 dota。, Start Time: 2393100
Text: 嗯，就人工智能的每一个应用其实都非常非常窄。它对于一个特细的目标，比如说在自动驾驶员里面，认人和认强的是两个完全不同的算法，完全不同的方法和方式。嗯，就是你很难想象，哎，我们现在认猫认狗出来了，我们用一样的方法认花不行，你要认花再写一个，嗯，从来从零开始重新来一个。, Start Time: 2415200
Text: 但我这么说可能说的稍微有点极端啊，但确实人工智能我们无法想象对人来讲，认大象认猫认狗认人嗯呃认人的脸呃，不是啊，但认人其他东西其实对我们自己来讲是一个东西。我们识别东西的能力是一个，但我们不能想象机器可以用一个方法来识别物体。嗯，每一个新的任务就需要一套全新的东西去练。, Start Time: 2436400
Text: 比如说练猫练狗这个东西现在已经二分法练了，再加个大象，就是一个全新的任务啊。对一个小孩来讲，猫狗大象是一个任务，多加个东西。但对机器来讲，这是两个完全新的任务。所以人工智能的横向扩展性其实挺弱的。完全没有他们宣传的那么好啊，这是第二个问题啊。呃，第第四个问题呢，, Start Time: 2462980
Text: 就是他对于就是语，特别是语义方面，他对于隐身和类比真的很难理解。嗯嗯，就比如说就是我看到他们一个实际的例子就。 john promised mary to leave，和 john promised to leave。 mary 我们知道第二个 leave 是分手离开的例子。, Start Time: 2483810
Text: 第一个 leave 就是离就是实际上物理意义的离开。嗯，像这两个这两个语句其实只有语序的变化，其他的词都是一模一样的。 john promised marry to live。但我们人就知道，第一个说的是他走，第二个说是分手。嗯，但你让机器来理解这个东西不行，, Start Time: 2505810
Text: 是因为在我们的语言里没有一个说的出来的东西，它就他这么用，指的是引申意这么用，指的是原意还不是没有任何规规则，没有这个规则。很多时候不同的词是不一样的，而且很多词是约定俗成的，它也不能总结结一个统统一标准。就是为什么为什么没有统一语法法，是是这个原因嘛。所以说机器呢在语义方面，, Start Time: 2527940
Text: 它处理这个引申意义和比意义的时候呢非常弱。而我们平时说话的时候，特别是我们可以这么说，特别是说话水平越高的人，嗯，他可不就是隐身意义和类比用的最多，这个人的表述会更好嘛。所以说机器有个领域很难啊，就是幽默。我们知道幽默很大程度上就是靠引身意义和类比去构成的。, Start Time: 2549060
Text: 嗯，所以机器没法写笑话，机器很难理解幽默，很大程度上跟这个就有很大的关系。 siri 有时候挺幽默的那是网络段子。对对，好像是是网络段子的机械输入。对，所以说从这个角度来看呢，我我我我我我在尝试表述一个观点，去第第深度学习习之嗯，它不是那个深深就深度学习之，, Start Time: 2573320
Text: 深是是深用了深度引引申义去诓骗。其他不能叫框骗啊，去误导吧。我我甚至我会觉得呃在机器学领域我挺有意思的东西。就是在很多其他领域，民众对一个科学词汇有误解，但科学家心里门儿清不是黑洞，不是那意思，黑洞指的不是有一个黑色的洞。嗯，跟视觉没关系啊，我们看也看不着。, Start Time: 2598250
Text: 嗯，对，但是我认为深度学习这个领域啊有一点点从业者和民众都对这个 deep 的误用有一点点嗯误解。因为比如说过去我认识的中国人想做心理诊疗类对话，人工学习智能机器人的人，我认识不下三个。嗯，现在都放弃了。嗯，因为在我看来，我我我说现在谁在做都可以直接放弃啊，, Start Time: 2619500
Text: 这根本不可能的事情。但你看，即使即使对于从业者，技术人员都会认为，唉，这这是可能的吧，我们要搞搞这个。所以我觉得这个深度呢是一个挺特殊的东西，属于民众和从业者都在误用这个词，会导致对他有嗯一些从业者是不是觉得这是个修辞方式，觉得这个东西很那那我觉得从业者打心里里觉得他可能具有那种生活中的深度，, Start Time: 2644830
Text: 所以才会想什么心理诊疗、自自动对话机械这种事儿啊，对，所以他其实也没有那么的 deep。嗯，那么在学习领域呢，就还有一个我们可能要实现人工意识很很重要的东西啊，就是跟学习高度相关的。我们知道人类学习有一个很重要的就是你的记忆，你记得住才学得会。那么机器如何获得记忆，, Start Time: 2667310
Text: 也是一个相当难的问题。首首先我们肯定不会认为这个电脑有记忆。虽然它里面装了好几百个记的数据，但这个跟记忆是不太一样的。首先呢记忆就需要有他自己，我们人啊有两个东西，第一，记忆自有其检索的方式。嗯，第二，记忆自有其叙述的方式。就我们人的回忆呃，有很多回忆是程序性或技术性的。, Start Time: 2693500
Text: 也就是说当这个记忆出来的时候呢，比如说我现在想我现在比如说我刚游泳还游的不是特熟，我一下水开始回忆游泳了，这是个程序性的记忆，它是先这样再这样再这样再这样。第二呢是陈述性记忆。比如说回忆我们俩之前吃饭、嗯吃吃吃吃炸酱面啊，那天的事情历历在目。嗯，这两种记忆呢都必须跟我作为前提视角。, Start Time: 2720270
Text: 当我做程序性记忆的时候，我是想我该怎么动。当我做陈述性记的时候呢，我是想我那天坐在那儿，赵霞坐在对面，我们俩吃那炸酱面，嗯，或者我可以这就更复杂了。我可以想象我是做照下的视角，想象他看着我他的视角呢对吧？也就是说我们的记忆啊是有一个基础视角的，是有一个基础的。, Start Time: 2745950
Text: 我现在才能够勾连起来记忆的，所以这个对机器来讲就就无从说起，该怎么赋予他这个。嗯，所以说基本上我们刚才大致梳理了一下，就是这些确实也是现在人造意识和人工智能前沿领域，嗯，就是机器常识，叫这个 computer common sense。第二个是机器知觉，第三个机器学习，, Start Time: 2770870
Text: 第四个机器记忆。机器记忆是最新的，是最没什么头绪的领域。就这四个领域也是现在做人造意识，实际去做研究最前沿的领域。他们在尝试赋予机器这些，因为这些东西呢可能会构成真够真正能够模仿人的行为和人的表现的机器的一些基础。当然我是分别说了这四个我觉得都搞不成的原因。, Start Time: 2795190
Text: 嗯，然后，但是我有一个问题啊，哎你说说说太好了。我觉得这个就人造意识和人工智能领域，它因为前面都加了机器这两个字，比如说机器常识机器，对对机器学习机器记忆机器。所以我觉得他可能从这个角度来说，他没有必要跟人工智能有特别完全的相似程度。还是人工智能。不是就跟人人真正人的跟人的特别高的相似程度，, Start Time: 2822370
Text: 它可能作为应用科学的一种，他可能有特别强的目标性。但是啊你会接受是是没有，就是咱们之前讨论过这个问题，对他有没有必要？真的跟人的意识一样，你说的特别好，就是我觉得可以让很多从业者听听你这句话话。但是你你知道第一，其实之前集合很多节目都说到过，人有这个梦，嗯，, Start Time: 2850120
Text: 就是人有当造物主这个梦，当造物主这个梦啊，你得造成那最高级的东西才算最牛逼。嗯，但我觉得没有，我们没必要啊，我我也觉得没必要。但是现在很多人嗯第一这个梦目的在嗯第二这个梦呢也有很多实践的地方。比如说我就认为应该完全抛弃这个心理诊疗这个但我们也知道心理诊疗我们，, Start Time: 2872340
Text: 但我们应该直觉上就能感觉到，这是一个很接近人的东西，对吧？嗯，你可能得先成为一个人，你才能解决其他人心理问题。但你又你也知道解决其他人心理问题，我敢说一定会是一个越来越蓬勃的产业。嗯，那那个公司得雇十个人在网上打电话跟人聊，你开发一软件，七乘二十四小时跑，, Start Time: 2897480
Text: 你你也有很大的商业利益。所以说我觉得让机器完全模拟人的行为和人的意识，不仅是我们的一个梦，它也确实在很多领域有有有很大的商业价值和潜力。反正我的观点就是我觉得不是特别有意义。就是从人类角度来说啊，就是就是我不我不确定现在的，比如说这个特别前沿的人造意识和人工智能的科学家们。, Start Time: 2918610
Text: 嗯，他们是因为有一个梦想要去实现这个才去做，还是因为有非常现实的问题可以解决才去做。你看对于那种大学里的科学家，这东西是一个智力比拼，是一个智性不智力比拼。说的有点俗气了，是一个人类知识追求的智信活动的比拼。是的，把谁搞出来了？这个在人类历史上名留青史，对首先对他们来讲呢，, Start Time: 2943520
Text: 是有纯粹的智信追求这回事的。嗯，而让他具有人造意识，那肯定是人工智能和机器领域嗯的最高奖杯了吧，就是那个山巅就在那嗯，你搞出这个来了，那这个牛逼疯了。嗯，那第二从商业领域呢，他们有个这个梦不管了，那搞出来之后赚钱嘛，是那写科幻小说的，我觉得可能是有这个梦或者是愿意构想这个东西。, Start Time: 2969340
Text: 肯定其实说实话，写科幻小说啊，跟这个东西真不真搞出来，其实没没什关系。对对对，完全不对，对，是真的。对对，因为其实我们就是科幻小说想的是，如果它实现了什么样，对其实它怎么实现这个过程是一个很落地的一个过程。对呃今天其实主要更多关注怎么实现？嗯，会说我还会说，, Start Time: 2994430
Text: 嗯，即使它真能实现，我也不认为它是个好事，是什么原因啊？有有有两个方面。呃，我我先说他们现在的这个成果啊，就是在上述几个领域呢，其实是还有一些成果的。就比如 common sense，就机器尝识这个领域。就首首先我说那个 word net 它已经做的特别特别好了，, Start Time: 3012930
Text: 就 word net 有很多很多知识性的尝试在里面了。这些知识性尝试呢，它主要在构建这几个要让机器来做。比如说里面有很重要的一块是行为和结果啊，比如说对人来讲，我随便说尝试啊，嗯你要吃饭就要先做饭。这个在我们来讲就是但对机器来讲，可呃嗯完全不是这么一个概念，, Start Time: 3030930
Text: 你就得有办法告诉他。 cook 是 eat 的前提，嗯， plant 呢又是 cook 的前提，你要不种了，你就没得做。你要不养，就对我们人来讲，这个链条关系是如此明显，而且都没得学历，从小长大不用人教你，你就知道这还只是吃这一回事啊。你想想生活中这样的事儿，, Start Time: 3054520
Text: 有多少机器得一个一个教像人就能演化哦，吃就得做，那穿衣服就得缝，那做的东西就得重，那穿的衣服也得重，我们就马上就来了。对，机器来讲，这是两个 totally different thing，你就得一个个教，这教到什么时候去了。所以教这个东西呢是挺累人的，但是为了最后这个东西，, Start Time: 3074600
Text: 把这 word d net 本身也就就电电商就得这么教，就一个个写。第二个呢是时间性的知识。比如说我们明显知道这个奥巴马在川普之前，嗯，机器可能有人知道，但我们方法不一样，我们根本不需要背年代就知道奥巴马在川普之前，但机器首先可能知道，但是你看机器知道呢，, Start Time: 3094180
Text: 比如奥巴马呃卸任川普上台，他是靠时间判断的那是一四年，这是零八年上的这是一零年上了大之后，所以我们人判断前后，你看我们是靠逻辑判断的。嗯，是因为奥巴马下台川普上台，我不用知道任何时间，他肯定在他之前。所以我们人类的很多时间性判断跟具体的时点没关系，不用知道哪年不用知道几分钟。, Start Time: 3117150
Text: 他在因果性和逻辑上是前后关系，他必须在那之前。嗯，所以我们要交给机器的时间性能，还不是教它时间，交时间位内以内就有你点打号，打号点就知道我们是要交给他。因果性和逻辑性跟时间前后有啥关系？嗯，这又得一块一块教。嗯，比如说对于政治人物上台这事儿吧，他这就叫前后关系。, Start Time: 3142850
Text: 对对，其他地方就得一个个教。嗯，第三种呢是一种是一些定性的尝试。就比如说人天人会觉得啥不好，就比如说蛇对大多数来讲呢是个坏东西，是那机器就得学哇，机器学这个也得学好多好多。但这个东西有一个领域是非常非常有用的，还真是挺有用的。所有这些东西啊，在医学领域是有用的。, Start Time: 3166320
Text: 你教给他一种因果上的时间性，比如这种病症，他的前兆病症是这个嗯比如医学上的恶感。比如虽然这个东西能治好人，但是太疼了。嗯，不光是太疼了，我再举个别的例子，是医学上的这个常识很重要的这脚气是个挺难治的病，对吧？嗯，但比如说有一个疗法，绝对能治好两千万，你治吗？, Start Time: 3190605
Text: 我还宁愿就长这个脚气了，是不是？对吧？所以人的治疗是个很复杂的东西，人人的治疗跟经济很有关系，而且他有适合生会行为。对，比如说我我感冒是挺难受的。你说行，我现在给你治好，下面要治好，你给我两万。我说那我忍着吧，我忍两周赚两万块钱，对吧？也就说这些常识你要交给机器，, Start Time: 3212210
Text: 说什么样的成本，对什么样的人能接受的。嗯，就这套东西现在其实运转的还挺挺有意义的。就刚刚试是那个 worallen 嗯，这个微软那个创始人之一，他有一个 AI 研究院是他的基金会来运作的。他虽然他已经驾鹤西归了，但这个研究院还在继续进行。嗯，这个研究院做的特别好的一个就是医学尝识构建。, Start Time: 3230970
Text: 嗯，因为医学尝识构建跟人工智能的自动化诊疗关系很大。嗯，但我得反过来说一句啊，这个跟之后的一个话题极其相关。为什么人工智能常识在西医这个领域有这么大的应用？嗯，我是因为西医的基础逻辑和方法是一套把人的整个身体和身体反应标准化、技术化的一个方式，对吧？嗯，在西医的世域里，, Start Time: 3254210
Text: 你的身体和我的身体是一样的。嗯，我们遵循同一套方法，在同一套统计的数据之下，对那个药对这个方式进行反应。嗯，所以在这个时候呢，你把常识加进去很有用。而这些常识呢对中医是没用的，是因为中医是一个人都不一样，每个人都不一样，是一个极其经验性的东西，而且是一个程度性的东西。, Start Time: 3283725
Text: 而不是一个性的性质性的东西。所以说这个一会儿会说到啊，我们社会应用人工智能和人造意识的一些风险。但 anyway 这是有用的对吧？这治治病当然有用了，我，而且连我都能相当正常的承认，这是这是有用的。嗯，你怎么感觉那么讨厌人工智能啊，那一会儿说啊就有两个核心原因，, Start Time: 3306500
Text: 我会非常非常讨厌人工智能。嗯，然后第三个是人造知觉，人造知觉当然也是现在最前沿的领域了。不管是听啊，尤其是看，尤其是视觉识别，嗯，那它能应用的领域非常广啊，就是我们能想到的自动驾驶只是其中之一。呃，政府监控啊等等等等，其实应用的领域真的非常非常广，这个是很多的一个。, Start Time: 3327460
Text: 但是现在呢有一个问题存在，其实我认为啊人造知觉不应该去做那种我们能知觉的东西，他更应该去做那种我们知觉不了的东西。就比如说我之前听的星际战士，那期星际战士不是好几个肺吗？对他不好像有一个肺就能够检测到有毒气体，对吧？嗯，还能过滤掉它。是的，我就觉得人造智能啊就不应该去检测，, Start Time: 3346265
Text: 不是人造智能去检测人工智人造知觉去检测。 PM 二点五就特别好，嗯，但他就检测我们能闻到的味道，我老觉得这个事意义不是特别大。嗯，就他能认猫认狗，我老觉得意义不是特别大，他能认一种我们看不到的小飞虫啊什么的，我觉得这意义挺大的。嗯嗯，所以我老觉得人造知觉的方向应该去搞那种我们我们人搞不了的，, Start Time: 3373740
Text: 而不是他认猫认狗的人知觉之外的。对他他他花那么长时间去教认猫认狗这事，我真觉得意义不是特别大，就是我们我们真的看的挺好的，而且我真不觉得这个全自动驾驶是个什么特别要紧的事。我我觉得其实家家都车车就是都这么开，不出不了什么大事儿，是你都不它变自动了也也也好不了，, Start Time: 3394040
Text: 好不了特别多。好，我们现在来说说这个人造意识的关键问题啊，我刚才介绍一下他们的事展，嗯，也就这些了，就人工智能进展很多。如果说到人造意识领域，现在做到的也就是这些。嗯，我会认为这个路线我现在说为什么根本上我认为它是搞不成的？它有一些问题，这个问题有一个基础。, Start Time: 3412800
Text: 为什么我们大家觉得搞得成呢？有两个基础。第一个基础，我们认为人的意识啊就是理性的做决定。嗯，现在有一种观点啊，特别这是一种很经济学的观点啊。嗯，经经济学研究人行为，经济学会认为啊本质上人哎，他们他们是有一种说法，说人本质上呢就是一套你习惯的反应机制，对吧？, Start Time: 3431910
Text: 嗯，首先他们认为人就是一个刺激反应体，这个刺激反应体最好的路子呢就是能够理性的做决策。嗯，在这个基础之下呢，他认为人造艺识能搞成。是因为如果你这么去想的话，他刺激反应体这种就是那个电脑先天的比人有优势，他还能干不好这个嘛，对吧？你只要让他能感受外界刺激，他一定能够理性的做更好的决策。, Start Time: 3457420
Text: 嗯，包括这个东西呢很多的情感啊，我们都给他做这个解释，做理性决策解释。比如说比如说哎呀健身这么累，这么辛苦，人为什么要健身呢？啊，因为会分泌内非肽内非肽让你爽。嗯，这个流泪人为什么流泪呢？啊，用眼泪里面有个这个元素啊，他让你爽。就是我们不光有这个基础的理念啊，, Start Time: 3476700
Text: 就是也在这个理念之下，用各种这个方式去解释人的意识和行为。嗯，反正合着最后就是为了爽，为了获得最大的爽的各种行为都可以用这个来解释。但首先我认为不是这样的，但这个我们一会儿再说。所以在这个情况之下呢，深度学习这个路子呢，人造意识呢就跟人的意识就突然一下就挺像的了。, Start Time: 3496960
Text: 嗯，反正你不就是一个事件反应机制嘛，在事件反应机制之中做理性最大化决策。那机器实现这个还不容易吗？它就不容易。首先我来说一下，就这个如果跳出这种比较狭隘的看法，比如荣格荣格这个东西虽然荣格神神叨叨的，嗯，但荣格这个这个区分是非常好的。人荣格认为，人有四种认知方式，, Start Time: 3517500
Text: 有两种理性，认知方式是 thinking 和 feeling 两种。我们可以把它说成是思考和感受。这个感受指的是直观的感受。外界价值。比如说很多时候我们面试的时候就会用到 feeling，觉得这人不行。嗯，或者是哎这人虽然简历上的东西都是特一般，但性肯定性。, Start Time: 3540620
Text: 嗯嗯，对另外两种非理性的方式是这个 sensation 和 into ter perception 和 intuition。就感知和直觉直觉呢荣格认为是人能够感知其他的动机。就比如一看陈光标啊，一看这个肯肯定不是真心做慈善人是来作秀的那比如说 perception，, Start Time: 3558440
Text: 就是对一东西，对一些东西的，对他人意图的，或者对他人感情的感知。哎，他这人之前可能挺伤心的，嗯，对，所有这些可能还没有超出感应反应机制，但其实已经超出了理性最大化机制了，嗯，理性最大化。这里面几乎只跟 thinking 相关。也就是说人如果如果我们认可荣格这个区分啊，, Start Time: 3576419
Text: 这个区分其实真的挺有效的。因为整个在职场上和现在大家可能觉得还挺愿意去标榜自己的一种这个心理测验。 MBTI 嗯，就是构建在荣格的这个四种认证方式基础之上的。所以说在这个情况之下呢，充其量这套理性，这段话只在模仿我们的 thinking。而其实 thinking 在日常生活中用的是真不多，, Start Time: 3599790
Text: 嗯，就是我们大多时候日常生活是靠其他三个，尤其是有时候 thinking，一会儿我们会说 thinking 的基础跟这个 perception 和 intertution 其实大有关系。而这些东西机器怎么来模拟它？其实绝不在现在人工智能和人造艺术路径之上。, Start Time: 3626610
Text: 嗯，所以我们人类的四大认知方式呢，它确实在某一个上能做。呃，首先我认为能做好这个已经特别牛逼了。但是所以我这是我认为为什么人造意识搞不定。第二个，我们来说，人为什么是一个超出事件反应机制的东西，我们要收回那个注意力。其实我认为注意力恰恰是事件反应机制的宗旨。, Start Time: 3641160
Text: 嗯，比如说我去看一个电影，我看个话剧吧，因为电影我没说话，我看看话剧吧，我看话剧其实就是啥也不做，我就看感觉就行了。舞台让他们打起来了，我也不去劝架，是里面有个特别恶心的人，我也不站起来骂他，不上来揍他。嗯，很多时候我们的注意力一句，包括你听歌的时候，你什么事件反应，, Start Time: 3664790
Text: 你就是不反应。嗯，就，现在就是不反应，他叫他哲学里有个词就叫叫 be holding 子状态。就人产生这种注意力的时候呢，就是恰恰是跳出事件反应，就是你就待着看。嗯，而很多时候我们就是这样，这才叫注意力。嗯嗯，你看美景，你啥也不做，你也不去拆那个山，你也不去砍那个树，, Start Time: 3687240
Text: 你就看。嗯。而哦人工智能和人造艺术的所有路径，它本质上是一个响应事件和产生结果的。比如你说我要编一个程，这个程序呢不响应结果，那就一个方法写时间呗。嗯， hointerval 五千秒，它本质上还是要结果的。你很难想象编一个没有结果的程，嗯，这就不是编程嘛，, Start Time: 3707850
Text: 这不是逻辑嘛。嗯，因此这个方式它就不可能去包含这个 be holding 后子这样的注意力，跳出事件反应状态的东西。所以这个东西人的注意力呢，其实是他模仿不了的。所以人是可以干这种没有逻辑的事情，没逻辑的事儿的。而且我现在我我我之前其实不是对那个神经科学还挺痴迷的吗？, Start Time: 3733180
Text: 我现在也有点拔草了，是吗？对，相当拔草，比如神经科学研究人的注意力机制是下丘脑产生的。嗯，我越看越觉得现在的神经科学跟这个为何怪不得他们俩玩的好呢？就跟这个人工智能人造艺术玩的好，他们俩方式特像。嗯，就现在神经科学的研究就是那种第一目标宏大啊，破解人类意识和思维的奥秘。, Start Time: 3755320
Text: 第二，看上去特有对。第二看上去特有启发啊，我们的注意力是下丘脑。下丘脑损伤的病人，注意力就会丧失下丘脑这个部分那个部分你就哇这很有意思，就跟人这个这个人工意识一样啊，就是唉，你看他现在能说话了，能翻译了。第三呢，实际上在现在还没有用，就就呃呃，现在用不了。, Start Time: 3779430
Text: 第四呢，他其实是在研究某种相关性，就大脑这块跟这个有关。但具体怎么搞的，不知道人工智能也一样，反而是反而是这个算法最后下围棋下的越来越好了。那具体怎么好的呢？就是个黑箱，在那个 depth 的那个逻辑层上面，我们也不知道。就我越来越觉得他们俩在搞一搞一回事，, Start Time: 3799550
Text: 嗯，提出一个特别宏大的目标，找到一些现在还没有用的相关性，但是对于本身机制呢也并不知晓的相关性。就我现在对这种东西就越来越兴趣比较寡淡啊，觉得可能实际上没什么用。第三个，我觉得人工智能人造一时搞不了的一个关键问题啊，就是身体感觉的丧失。就我们如果无法赋予机器一副身体的话，, Start Time: 3819140
Text: 它就不会有经验，不会有体验，嗯，不会有感受，也不会有自我。也就说这里面有个很有意思的观点，到底是无感在前，就是掩耳掩耳鼻舌，是感觉在后还是其实是感觉在前，无感在后。对，就是先有感觉才有看，就不是像视网膜。嗯，视网膜，那是在我们人身上啊，是有感觉之后被我们的感觉牵动的东西。, Start Time: 3842780
Text: 所以现在机器有视网膜了，机器有耳膜了，嗯，机器可能有这个皮肤了，都能给机器做出来。但是我们认为这个就可以通达身体，感觉不是这个在人的感知上是后一步的东西。嗯，先一步分是你的感觉。我说个简单的，我们想个问题，为什么小孩学东西所需要的数据量，比如小孩认猫认狗？, Start Time: 3872230
Text: 嗯，他今天认这只猫狗，下次再出去认猫狗很容易。嗯，为什么机器认个猫认个狗他妈这么费劲，而且小孩认猫认狗和认大象认长颈鹿都是一套东西，机器认不了呢？是因为机器的经验啊，所有我们认为能变成知识的经验都是原子化的这个这个这个这个而人的经验这么说吧，一个人经历特多，, Start Time: 3896110
Text: 不需要靠机器跑，一个数据整理啊，经验就经验在你脑子里面是自动勾连的。嗯，你经验一多，你不用靠自己去反思，自己去琢磨，很多时候他自然就就就就勾连起来了。小孩认猫认狗，认那个猫，那个狗不需要他想要那个猫产生联系，这种能力对这个能力是自然的。所以这个能力恰恰是人的感觉的基础。, Start Time: 3921480
Text: 我们就是在感觉着万物之间的联系，嗯，感觉这个世界这儿跟那儿挺像的，哪哪都挺像的。这个是我们的基础，而我们的感觉不是像洛克那样的，而是休磨那样的。是，所以我们现在给机器给他五官给他 sense data 根本就不是一个路子。嗯，所以从这个路子呢，你根本就没有人这样的效率。, Start Time: 3944220
Text: 他可能学围棋确实比我学的快啊，但是他没有别的效率，像我这样把世界联系起来，嗯，而没有这个呢他就没有感觉，嗯，就只有经历而没有体验，没有体会，也不会有感知，他也就不会形成真正像我们这样的常识。对，在这个情况之下呢，因此他也不会有我们这样的。所以说这里面有很重要的东西，, Start Time: 3965420
Text: 就是人的感知跟 API 的区别。像我们给那个 API，这个我们可能别人都知道啊，就是个数据传输接口。对接口。我们现在给人造意识的感官呢，其实是接口式的。对啊，就是这是一个是它不是接口式的，它就是接口。嗯，这是个硬件，是个视觉 sensor。他把这个数据传给接口，, Start Time: 3988305
Text: 前面有个区分接口，套接口要什么就接口要什么，给他什么。然后接口有一个数据规范，只要是这个呢就给个这个反馈，是这个呢就给个这个反馈。但人的经验和感觉不是接口式的。你的视网膜和人的感觉不是视网膜给你的感觉一个信号，你感觉接受一个信号，再去做拆分。我们有时候做这个比喻，, Start Time: 4008540
Text: 但实际不是实际。我们都说了，你有注意力机制，你有视而不见，你的感觉跟它是一套的。你的感觉在统一着它它不是切分的接口关系。所以这是一个我觉得一个根本上我们对人的身体和机器感知的一个很重大的区分。我们在用 API 去想象的去比喻它，但人其实不是，而且还有一个人的逻辑和人的非逻辑不是单一的。, Start Time: 4028250
Text: 嗯，很多时候人的思考和决策过程是这段逻辑的阶段，非逻辑接一段逻辑，搞一段非逻辑，就像机器的赌，就是随机数，人的赌还不是随机数。嗯，他先有一些基于常识和逻辑的推断，在这个里面里面他可能随机一下。嗯，因此呢人的思维和意识逻辑从来不是纯粹逻辑的，或者纯粹非逻辑的，, Start Time: 4054900
Text: 也没有一个范式。这段非逻辑的那段是逻逻辑的永永远快快速交织在起起的。他的很思思考过程，跳跳的是纯粹靠直觉，胡他妈猜的嗯，可能胡猜完了那一步立马是特特严谨的逻辑辑断。而再胡猜一下，你玩游游戏你也知道吗？很多时候为什么走向中应该是胡猜，但是胡猜之后，你的方法是极其逻辑。, Start Time: 4079060
Text: 但是换这个墙为什么要这么做？对，也就是说人造意识呢很难完全的模拟。这个什么时候用荣格式的直觉。胡猜什么时候把这个个逻辑这段接上来？就是现在有的人造意识的路径或人工智能路径在尝试。哎，我们能不能用随机数这个路子，但人到底能不能做出真的随机数，这还是个两说啊，, Start Time: 4100020
Text: 说说对对，这个问问题我实实不不深入了。那即使他能卖，嗯，就是即使能搞出，哎，我们搞出这个随机直觉这块了啊，真的随机了，真的随机了。胡猜呢咬了，这还不是人的意识，人的意识不是要么逻辑，要么胡猜。是的，它的逻辑和胡猜是交织交织在一起的这个东西，机器要去模拟，这个就相当相当困难。, Start Time: 4125910
Text: 对，然后我我我然后我我基本上除了说最后那个危险之前，嗯，就是关于人造意识，为什么搞不了我我基本上我的观点说了，这搞不了之后，我还是得说一个，就是为什么我们这么痴迷，为什么全身心相信这个，而且有这么多人还挺愿意去相信这个呢？我得说一下，但是我说完这个可能会喷的挺厉害。, Start Time: 4146095
Text: 但是我还是得说，就是为什么现在这个观念念这迷说的就是世界本质上逻辑辑和数学的一东东都能能还原基基础原理支配。就这个这个这个观观念还挺迷人，包括意识虚妄的啊是虚假的。我是觉得这个观念这么迷人啊，跟这个平民社会关系挺大。第一，我们想人人平等。第二，其实人人很不平等，, Start Time: 4170490
Text: 那乔丹打篮球跟我们俩打篮球，那这不是这不是一个量级的。乔布斯的想法跟我的想法还不是量级的，这种想法给了人人平等又极不平等的这个社会现实一个终极解释。嗯，就是从本质上乔布斯聪明人比我聪明多了，那还是被电化学反应，一套电化反应。我这边也是电化学反应，它最后都能还原为某种数学逻辑公式，, Start Time: 4194390
Text: 反正就是这样的。嗯，而且我们还希望有人造艺术的，就是说他比我们都要牛逼十万倍。当他一出现的时候呢，乔布斯跟我的差距呢变得很微弱啊，就是五十个小百不，那乔布斯乔布斯一百我五十，现在看着挺大的啊，人造一识搞笑的跟弄到两千来的。乔布斯跟我这个比例跟他一比呢，也就没什么。, Start Time: 4218320
Text: 所以我有点认为，现在有一种社会思潮会愿意相信第一历史不是人决定的，人跟人我们没那么大差异，本质上是一样的，都能还原某种宇宙公式啊，逻辑数学原理就是那个斯宾诺上那条自然神论的东西，其实现在变成一种数学神论，逻辑神论这么容易被接受受他背后有一个心理动机在作祟。, Start Time: 4237340
Text: 就是我们进入这个社会之后，其实过去我们没那么在意人人平等啊，就是你要只是不是贵族，你就觉得就就该这样，或者是就这样。但今天我们第一接受了人人都是平等的。第二呢实际上就是挺不平等的。是，所以我们想找一个终极的平等的观念。嗯，好，这是我容易被喷的。这个说呢？好，, Start Time: 4259680
Text: 我说一说为什么即使人工智能能搞成为不希望呢？我先说第一个就是一个产业工人，嗯，就是人工智能领域啊，会产生很多的 shpe job。我说一个之前我们说到的，但我为他想了解决方案的。我们之之受到到人工智能画和和做音乐没什么了不起的。对，因为他不知道哪个好。哎，, Start Time: 4278700
Text: 我后来给他想了解决方案，他一下来三万首巴赫的歌，然后就就 spoditify 网易音和虾米上去播。嗯，大家点红心，哪个最高，哪个就最好。因因判断了，那他就学习了，他他他不能学习。于是我们想出了一个机制，一起来挺低成本的。真的选出了最决方的的。我们个情况下呢，, Start Time: 4300740
Text: 我们还真的可以把作曲家都开了。我们用这个方式搭配这个机制，用人工智能选出最棒的最受欢迎的歌。然后他们再拿这个歌曲词儿也行啊，选何振信的歌。但你要想这样的话呢，这些歌里面一定有很多那种特烂的歌。网易音乐就会出一个服务，一个人工智能金牌 VIP 服务。我一个月给两百，, Start Time: 4321320
Text: 就别给我推送这个歌，你就把这歌里面最后选出来，最好推送给我就行。因此靠人去选择哪些好的，成为了一种新的特权和不平等。有些人给不了这个钱呢，你就得参与这个选择过程。有些人钱给足了呢，就可以免于选择直接享受成果。嗯，这就是那些描边的人和选猫猫狗狗的人，就是社会最底层的劳动力。, Start Time: 4345010
Text: 而我们这种稍微比他们高一点的经济阶层呢，就可以直接享受什么成果。未来这种东西越多，就越需要这样的劳力。就越来越多的人可以靠他们的特权和地位去享受我们筛选出来的成果。嗯，而且这里面还有一个风险在就是人工智能的现代这种算法，即即使不改啊，就是一个反向回馈算法，, Start Time: 4370080
Text: 需要大量用继续学习，一是大量，二是它极容易受到短期不良样本的冲击。就假设这个人工智能自动驾驶汽车，这个世界上有一个组织，就是要搞乱这个，他们用穿特定的衣服，在特定的场合。呃，假设汽车公司对撞死人给取极高的权重，这是肯定的嘛，你要撞死人肯定。对对，这个算法权重感觉极高。, Start Time: 4392910
Text: 第一天这个组织导致这个机械撞死四十个人，这四十个人极大的冲击到原来算法，第二天他就可能会在路上随机的撞死五千个人，就这套算法很难抵御短期的特殊样本的冲击。这套算法也很容易 hack。比如说我们知道怎么让他听不懂话，我说递归性的话，他就听不懂视觉识别也是怎么去 hack 那个识别。, Start Time: 4414620
Text: 方法很简单，比如现在人脸识别就是戴墨镜，嗯，一旦有墨镜，眼睛周围的关键点描不出来就认不出来是谁。嗯，很容易 hack。所以这个东西不光会带来这种新的劳逸的风险，它也会带来社会的系统性风险。假设最后全球有一个人工智能的汽车驾驶算法。那这个算法里这边 hack 第二天不就是交通全瘫痪嘛，, Start Time: 4435890
Text: 嗯那它本身也是一个中心化的，非常不稳定的解决方案。嗯，我再说第三个，其实最糟糕的方式现在已经出现了。我绝不认为有一天我们能发展出足够安全的自动驾驶技术，能够适应自动驾驶与非自动驾驶混合的状态。嗯，就是混行式自动驾驶绝搞不定的。但自动驾驶一定有个最简单的方式，, Start Time: 4457810
Text: 我们单辟出两条道来，这两条道路只开自动驾驶汽车。是嗯也就是说现在已经有一个方向了，因为其实飞机的自动驾驶早就实现了。嗯，这客机嗯它就是靠一套严格的航空路线管理来实现的，我们完全可以把它用到城市交通上来。我们直接开辟两条，这两道就拿墙隔开，就都拿墙隔开，这不就完了吗？, Start Time: 4482840
Text:  BRT 嗯，对，就是 BRT 它。但它的风险什么呢？它的风险是我们必须面临，我们要建造一个高度标准化统一社会的风险一样。为了让他能认出每个人的脸那样认不好认，衣服上缝个芯片还不好认吗？身体里值一个 RFID 芯片还不好认吗？也就是说为了让这个到了这一步，, Start Time: 4505320
Text: 对为了让这个搞不太好的人造艺和和人工智能，真的能够大规模高效运用，我们不去增强它。我们把社会统一化，标准化嗯就行了。而这个早就是就是资本本义本身就是一个社社统统化、标准化的。我们现在喝什么饮料瓶都长那样，对碳酸饮料都是那样。嗯，喝那个牛奶都是那个包装那个立乐砖利乐砖利乐包、, Start Time: 4527710
Text: 对外整包都这样。也就是说人工智能会进一步加剧。如果我们想应用它的话，我们不得不付出一个代价，我们进一步去加剧社会的标准化程度。嗯，我们一定会因为这个原因迎来一个特别无趣、特别无聊的。而且对我们自己的自由有特别大影响的社会环境。就为了自己不要开车，就为了能够快速给你认出来和等等的事情，, Start Time: 4550700
Text: 这个代价其实就太大了。而且在这个带压之下呢，我觉得人造艺识可能也能实现。只要让我们足够蠢，只要让我们丧失这种直观能力，丧失这种经验能力，让我们变成一个只会做短期最大化经济决策的响应的人，丧失注意力的人，那可人造意识就实现了。嗯，我们只要把我们变得足够统一，, Start Time: 4575810
Text: 把我们变得足够愚蠢，就可以让人造意识反过来撵上我们就有我们这样的人造意识，也可以让他好好用。我觉得这个是最大的一个风险，而这个风险现在正在发生。刚才我说的西医那个其实就是一个西医，就是一个快速将身体标准化，将身体统一化，用统一方法去对待的一个方式。嗯，而西医跟人工智能的结合一定会出现很多这样的问题。, Start Time: 4598680
Text: 我举个实际的例子，就是美国有一个方法可以判断呃，具体的病我就不说了，就是在儿子呃就孩子在母胎里面的时候就能判断一些先天遗传疾病，嗯，嗯，是靠扫描的方式，而且是靠人工智能来做的。其中有一次他们换了一个新的机器，那新的机器的精度比上个机器高。因此在上个机率高的情况之下呢，, Start Time: 4624080
Text: 会产生一些白噪音点。这个白噪音点跟过去诊疗过程中的一个病症刚好是一样的哦。换这个新的机器之后，新生患儿患了一个病的比例大幅度上升。嗯，好多人因为这个原因把孩子留掉了，嗯，或者让孩子接受了，还在母胎的时候就接受了一个治疗。而这个治疗本身是有风险的，来了根本就是技术手段造成的系统性风险。, Start Time: 4646720
Text: 嗯，这个东西你你这种机东西用的越多，人工智能在西里自动化用的越多，就越来越容易出现这种事儿。这种事儿如果全靠医生来啊，所以就们再换个方法，而不是。但你让机器自动来的话，就那就是嗯就这种东西会越来越多，这种风险会越来越大。所以不管是把我们的身体，还是把我们的社会变成一个统一化社会。, Start Time: 4672130
Text: 一个统一的标程本身就是有很大的风险和不爽在里边的。嗯，所以这是我为什么即使他搞得成，我也不希望他搞成的原因。不过我我当时刚才有个想法是嗯把人搞成统一化来适应人工意识，技术的难度很可能和实现人工意识难度一样大，这可能是双向的一个阻力。对对对，可能会指向两方，, Start Time: 4693370
Text: 都其实都不会实现，都不容易。对他当然很难。但是我觉得一旦他跟经济利益和权力捆绑，他可能有一强强制性的手段，就就就能够推行他。对对，但感觉是虽虽然是未来的事，但是还是是一挺好的。小说的那种题材是对对对对对对对，也没有特别未来了，我觉得是对。嗯，而且但你这是一个悲观的观点啊，, Start Time: 4715350
Text: 我非常悲观，我我我极其悲观悲观到我认为呃，不管是人工智能深度算第一啊，我不认为我们还能搞出更新的算法。第二，我认为现在算法的技术上限，我们基本上已经摸到了就能干这个了。就是全自动人工驾驶汽车，人车混行绝不可能出出现。就真的能跟你说话的机器人不可能出现。就是之前大家最呃幻想最多的就是特别智能，, Start Time: 4738630
Text: 惟妙惟肖的性爱机器人可能搞不了。对，可能搞不成。对对对，可能弄不了。对对，反正我对这些是持非常悲观的态度，而而且这个悲观呢我也乐见其成，就是他搞不成挺好。嗯，对，搞不成我们社会的好点的是，但是现在这个人工艺识、人造艺识和人工智能确实是很火很火非常火。对，但是说实话说到现在，, Start Time: 4765930
Text: 它最火的应用的最好的领域就是只能推荐嗯 youtube 虾米今日头条是暴璃法智能推荐，其实恰恰是因为 youtube 的这个方法，它在促成 youtube 上视频的标准化。嗯，因为这个算法的存在，视频的挺厉害的，视频的生产者再去适应这个算法和标准。嗯，他在导是视频节目的单一化，, Start Time: 4790690
Text: 比如说最简单 youtube 这个标准就特别适合。如果你要做个频道啊，你的视频时间真就是十分钟，而且你必须最好让你这个频道里面所有的视频都是收的非常紧。在一个主题和一个题材之上，嗯，是最容易被这个算法推荐的。嗯，所以你要想要更多的流量的话，你必须适应这个个适应这东西你就被它标准化，, Start Time: 4815900
Text: 它其实是对多样性的一个扼杀嘛。是的，而且其实 youtube 的封面，我觉得现在看多了之后，也发现它都是特别特别标准，特别标准。哎， youtube 现在可以自动给你生成一个适合你风格的封面，特别厉害。那个对对对对对，而且而而且它是极端标准化的对极端标准，, Start Time: 4837860
Text: 他知道哪个封面会对对对，容易点。对对我我不得不说我对人工意识的观点是我们能在现在这里说这样的这个非常技术悲观的观点。嗯，是因为技术在进步，所以我其实我我是我倒无所谓，他实不实现。我主要是认为这个我需要看到人类文明往前进嗯，就是在往前动。因为我发现希望人类文明不再前进的观点，, Start Time: 4855720
Text: 依然是人类文明进步的一种产物。认为人类意识不能被认为人类意识不能被制造出来的观点是对人是对意识的，想要了解意识的冲动产生的东西。嗯，所以我要的倒无所谓，他做不住我我的意思就是说这种冲动是是文明，嗯，就我我就对就是说很难想象，很难想象人人造智能是什么样，那就去做这个想象。, Start Time: 4884790
Text: 如果你一眼看不到它的边界呢，你就去找这个边界。如果你看到这个边界呢，就去翻阅这个边界，就是这是我心目中人类之所以为人的对这个点，所所以一一其实也有发展。就比如说呃可能有些批判是消极的批判啊，认为他做不成。丈夫们小孩想做不成吧。对，就还有一种是积极批判，我认为他做不成，, Start Time: 4914430
Text: 恰恰因为他做不成。我们这边要做这摊摊子事儿。对，认认此人类文明前进。因我我认为明明前进可能不不同于技术术前前有时候技术太前进了，文明就是后退了或甚至文明会因为他的原因被压抑的后退，有时候技术走不动了吧。哎，文明发展的挺好，就是因为有时候确实苦难，让文明更快发展。, Start Time: 4935950
Text: 有时候特别安逸的地方，文明就反而不发展了也挺多的嘛。所以人工智能的领域其实很很神奇的。就是说我觉得人工智能的探讨是这个工业文明开始迭代，进入新下一个下时代的一种一种状态。就是说下一个时代，对就是信息相关技术开始挑战。工业时代是我们认为的人类的神圣性嗯呃特别对这个事情就你会发现，, Start Time: 4954770
Text: 这不是我们这个时代的人能说明白的事。为你们俩这个观点一个一个特别理性，一个还是有点感兴趣的。但我认认为它不是工业文明进入下一个文明的一个象荣。我认为它是工业文明走向极甚走向极端的。最后那一下最后一下，最后就是通过他，我们发现哦哦工业文明最远就走到这儿了。对我是认为我就这这这只是一个猜测或者一个我的判断，, Start Time: 4980660
Text: 就我会看到哦，工业文明就是这样了的一个契机。对，反正我听完三期节目啊，不是对这个人造艺是有什么样的就是感受，反而觉得人类的意识实在挺牛逼的，非常非常的，而而且有复杂杂的，比我们想象要复杂太复杂了。对，太奇特了嗯嗯，非常奇妙的一种意识。而且我觉得我们会来机核这样一个如此所有踩完不着调的节目聊这个事情，, Start Time: 5005900
Text: 也证明了我们这个时代发展到这一步的。对，就所有人都在调到底是什么。对，而且你说你说机核是一个特别轻度，特别不着调调的地方，那个大多数可能不是这么看的。对客观说说集合已已经相当硬核了，客观上说其实挺不着调的，是吗？对，所以我觉得说明我们踩在一个坎上，是嗯就这个坎什么坎上了是吗？, Start Time: 5032660
Text: 对，反正今儿我来说，人类文明踩不着上，对，集合踩在坎坎上，然要集合踩壳上，照照特特别慌是吧？就不是所有人都踩在坎上了，是吗？对，而且对他说所有人都还踩踩着，都踩着壳集合踩踩壳上了。对对，我们就是应该为这种事情去争论，去痛苦，去去思考。对，因我我们会别踩坎坎等我。, Start Time: 5056120
Text: 对，所以我们先把这一定定把这个儿放过去。对对对，差不多是这个样子。对，反正我还愿啊这个这个这个系列搞完了，看下个系列再搞个啥再说吧，拜拜。行，那咱们就谢谢大家收听哈，谢谢大家收听。嗯，那就，咱们未来啊在新一时代新时代代见，对对对对对，好拜拜拜拜拜拜。, Start Time: 5075460
